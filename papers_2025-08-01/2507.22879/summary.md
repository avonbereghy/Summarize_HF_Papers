# RecGPT Technical Report

**Paper ID:** 2507.22879

**URL:** https://huggingface.co/papers/2507.22879

## Summary

## Executive Summary
The **RecGPT** technical report proposes a *next-generation* framework for recommender systems, shifting the focus from **log-fitting** objectives to **intent-centric** design. By integrating *large language models* (**LLMs**) into key stages of the recommendation pipeline, RecGPT aims to capture users' *evolving and latent interests*, ultimately leading to a more *sustainable and mutually beneficial* recommendation ecosystem. The report highlights the potential of **LLM-driven** design to foster *increased content diversity and satisfaction* for users, as well as *greater exposure and conversions* for merchants and the platform.

## Key Contributions and Findings
* **Rethinking Recommender Systems**: The report proposes a new design paradigm for recommender systems, placing *user intent* at the center of the recommendation pipeline, and integrating **LLMs** into key stages of user interest mining, item retrieval, and explanation generation.
* **Multi-Stage Training Paradigm**: RecGPT incorporates a *multi-stage training paradigm*, which integrates *reasoning-enhanced pre-alignment* and *self-training evolution*, guided by a *Human-LLM cooperative judge system*, to effectively align **LLMs** to domain-specific recommendation tasks.
* **Intent-Centric Design**: The report demonstrates the effectiveness of **intent-centric** design in capturing users' *evolving and latent interests*, and providing *increased content diversity and satisfaction* for users.
* **Real-World Deployment**: RecGPT has been fully deployed on the *Taobao App*, with online experiments demonstrating *consistent performance gains* across stakeholders.
* **Human-LLM Collaboration**: The report highlights the potential of *Human-LLM collaboration* in guiding the training paradigm and improving the overall performance of the recommender system.

## Methodology Overview
The methodology involves **large language models** (**LLMs**) and a *multi-stage training paradigm*, which includes **pre-alignment**, **self-training evolution**, and *Human-LLM cooperative judge system*. The *pre-alignment* stage uses *reasoning-enhanced* techniques to align the **LLMs** with the domain-specific recommendation tasks, while the *self-training evolution* stage refines the model through *self-supervised learning*.

## Results and Performance
The report summarizes the key results, highlighting **consistent performance gains** across stakeholders, including *increased content diversity and satisfaction* for users, and *greater exposure and conversions* for merchants and the platform. The results demonstrate **improved metrics**, such as *click-through rate* and *conversion rate*, with *significant improvements* in *user engagement* and *merchant exposure*.

## Limitations and Future Work
The report mentions the need for further research in *scaling up* the **RecGPT** framework to accommodate larger and more complex recommendation tasks. Potential future directions include *exploring new architectures* for **LLMs**, *improving the efficiency* of the *multi-stage training paradigm*, and *investigating the application* of **RecGPT** in other domains.

## Practical Applications
The **RecGPT** framework has potential *real-world applications* in various domains, including *e-commerce*, *content recommendation*, and *personalized advertising*. The report highlights the potential of **LLM-driven** design to foster a more *sustainable and mutually beneficial* recommendation ecosystem, with implications for *improved user experience*, *increased revenue*, and *enhanced competitiveness* for businesses and organizations.

---

**Authors:** Chao Yi, Dian Chen, Gaoyang Guo, Jiakai Tang, Jian Wu, Jing Yu, Sunhao Dai, Wen Chen, Wenjun Yang, Yuning Jiang, Zhujin Gao, Bo Zheng, Chi Li, Dimin Wang, Dixuan Wang, Fan Li, Fan Zhang, Haibin Chen, Haozhuang Liu, Jialin Zhu, Jiamang Wang, Jiawei Wu, Jin Cui, Ju Huang, Kai Zhang, Kan Liu, Lang Tian, Liang Rao, Longbin Li, Lulu Zhao, Mao Zhang, Na He, Peiyang Wang, Qiqi Huang, Tao Luo, Wenbo Su, Xiaoxiao He, Xin Tong, Xu Chen, Xunke Xi, Yang Li, Yaxuan Wu, Yeqiu Yang, Yi Hu, Yinnan Song, Yuchen Li, Yujie Luo, Yujin Yuan, Yuliang Yan, Zhengyang Wang, Zhibo Xiao, Zhixin Ma, Zile Zhou
