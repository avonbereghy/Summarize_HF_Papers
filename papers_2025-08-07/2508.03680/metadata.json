{
  "id": "2508.03680",
  "title": "Agent Lightning: Train ANY AI Agents with Reinforcement Learning",
  "authors": [
    {
      "_id": "68940ca8741a16f544fbce6b",
      "name": "Xufang Luo",
      "hidden": false
    },
    {
      "_id": "68940ca8741a16f544fbce6c",
      "user": {
        "_id": "6466d323ac657f60661d2778",
        "avatarUrl": "/avatars/62f70630cdf1c252b80b4d5eaa5a4150.svg",
        "isPro": false,
        "fullname": "Yuge Zhang",
        "user": "ultmaster",
        "type": "user"
      },
      "name": "Yuge Zhang",
      "status": "claimed_verified",
      "statusLastChangedAt": "2025-08-07T10:39:35.704Z",
      "hidden": false
    },
    {
      "_id": "68940ca8741a16f544fbce6d",
      "user": {
        "_id": "6455f5cababbbbd3486d6ee3",
        "avatarUrl": "/avatars/b6c8f65fd2bef8a00aa3269856ea238e.svg",
        "isPro": false,
        "fullname": "Zhiyuan He",
        "user": "hzy46",
        "type": "user"
      },
      "name": "Zhiyuan He",
      "status": "claimed_verified",
      "statusLastChangedAt": "2025-08-07T10:39:32.667Z",
      "hidden": false
    },
    {
      "_id": "68940ca8741a16f544fbce6e",
      "name": "Zilong Wang",
      "hidden": false
    },
    {
      "_id": "68940ca8741a16f544fbce6f",
      "user": {
        "_id": "64c20f8264e3e59137d88742",
        "avatarUrl": "/avatars/8d3f6f2cbce053969866388ce75c602f.svg",
        "isPro": false,
        "fullname": "Siyun",
        "user": "SiyunZhao",
        "type": "user"
      },
      "name": "Siyun Zhao",
      "status": "claimed_verified",
      "statusLastChangedAt": "2025-08-07T10:39:29.935Z",
      "hidden": false
    },
    {
      "_id": "68940ca8741a16f544fbce70",
      "name": "Dongsheng Li",
      "hidden": false
    },
    {
      "_id": "68940ca8741a16f544fbce71",
      "name": "Luna K. Qiu",
      "hidden": false
    },
    {
      "_id": "68940ca8741a16f544fbce72",
      "name": "Yuqing Yang",
      "hidden": false
    }
  ],
  "abstract": "We present Agent Lightning, a flexible and extensible framework that enables\nReinforcement Learning (RL)-based training of Large Language Models (LLMs) for\nany AI agent. Unlike existing methods that tightly couple RL training with\nagent or rely on sequence concatenation with masking, Agent Lightning achieves\ncomplete decoupling between agent execution and training, allowing seamless\nintegration with existing agents developed via diverse ways (e.g., using\nframeworks like LangChain, OpenAI Agents SDK, AutoGen, and building from\nscratch) with almost ZERO code modifications. By formulating agent execution as\nMarkov decision process, we define an unified data interface and propose a\nhierarchical RL algorithm, LightningRL, which contains a credit assignment\nmodule, allowing us to decompose trajectories generated by ANY agents into\ntraining transition. This enables RL to handle complex interaction logic, such\nas multi-agent scenarios and dynamic workflows. For the system design, we\nintroduce a Training-Agent Disaggregation architecture, and brings agent\nobservability frameworks into agent runtime, providing a standardized agent\nfinetuning interface. Experiments across text-to-SQL, retrieval-augmented\ngeneration, and math tool-use tasks demonstrate stable, continuous\nimprovements, showcasing the framework's potential for real-world agent\ntraining and deployment.",
  "url": "https://huggingface.co/papers/2508.03680",
  "pdf_url": "https://arxiv.org/pdf/2508.03680.pdf"
}