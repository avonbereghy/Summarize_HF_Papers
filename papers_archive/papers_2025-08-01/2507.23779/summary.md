# Phi-Ground Tech Report: Advancing Perception in GUI Grounding

**Paper ID:** 2507.23779

**URL:** https://huggingface.co/papers/2507.23779

## Summary

## Executive Summary
The **Phi-Ground Tech Report** presents a comprehensive study on advancing perception in *GUI grounding*, a crucial component for **Computer Use Agents (CUAs)** to execute actions. The report highlights the limitations of current *end-to-end grounding models*, which achieve less than 65% accuracy on challenging benchmarks, and introduces the **Phi-Ground model family**, which achieves *state-of-the-art performance* across five grounding benchmarks. The report provides an in-depth analysis of the training process, from *data collection* to *model training*, and discusses the importance of *perception tasks* in CUAs.

## Key Contributions and Findings
* **Advancements in GUI Grounding**: The report introduces the **Phi-Ground model family**, which achieves *state-of-the-art performance* on five grounding benchmarks, including *ScreenSpot-pro* and *UI-Vision*.
* **Empirical Study on Training**: The authors conduct an *empirical study* on the training of grounding models, examining details from *data collection* to *model training*, and provide insights into the construction of *grounding models*.
* **Performance Evaluation**: The report evaluates the performance of the **Phi-Ground model family** on various benchmarks, achieving *high scores* of **43.2** on *ScreenSpot-pro* and **27.2** on *UI-Vision*.
* **Implications for Perception Tasks**: The authors discuss the implications of their findings for other *perception tasks*, highlighting the importance of *GUI grounding* in **Computer Use Agents**.
* **Open-Source Availability**: The report provides an *open-source implementation* of the **Phi-Ground model family**, allowing for further research and development in the field.

## Methodology Overview
The methodology involves **data collection** from various sources, followed by *data preprocessing* and *model training* using **deep learning techniques**. The authors employ *transfer learning* and *fine-tuning* to adapt the models to specific *GUI grounding tasks*. The **Phi-Ground model family** is developed using a combination of *convolutional neural networks (CNNs)* and *transformer architectures*.

## Results and Performance
The **Phi-Ground model family** achieves *state-of-the-art performance* on five grounding benchmarks, with **bold** metrics including:
* **43.2** on *ScreenSpot-pro*, outperforming existing models by a significant margin
* **27.2** on *UI-Vision*, demonstrating the effectiveness of the **Phi-Ground model family** in *challenging scenarios*
The report also provides *comparisons* with other models, highlighting the advantages of the **Phi-Ground model family** in terms of *accuracy* and *efficiency*.

## Limitations and Future Work
The report mentions the following limitations:
* The **Phi-Ground model family** is limited to *GUI grounding tasks* and may not generalize to other *perception tasks*
* The models require large amounts of *labeled data* for training, which can be time-consuming and expensive to obtain
Potential future directions include:
* Exploring the application of the **Phi-Ground model family** to other *perception tasks*
* Developing more *efficient* and *effective* methods for *data collection* and *model training*

## Practical Applications
The **Phi-Ground model family** has potential *real-world applications* in:
* **Computer Use Agents (CUAs)**, such as virtual assistants and automated testing tools
* **Human-Computer Interaction (HCI)**, where *GUI grounding* is crucial for effective interaction
* **Accessibility technologies**, where the **Phi-Ground model family** can be used to develop more *intuitive* and *user-friendly* interfaces for people with disabilities.

---

**Authors:** Miaosen Zhang, Ziqiang Xu, Jialiang Zhu, Qi Dai, Kai Qiu, Yifan Yang, Chong Luo, Tianyi Chen, Justin Wagle, Tim Franklin, Baining Guo
