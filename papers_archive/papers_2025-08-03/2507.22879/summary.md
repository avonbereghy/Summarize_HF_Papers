# RecGPT Technical Report

**Paper ID:** 2507.22879

**URL:** https://huggingface.co/papers/2507.22879

## Summary

## Executive Summary
The **RecGPT** technical report proposes a *next-generation* framework for recommender systems, shifting the focus from **log-fitting** objectives to **intent-centric** design. By integrating *large language models* (**LLMs**) into key stages of the recommendation pipeline, RecGPT aims to capture users' *evolving and latent interests*, ultimately improving the overall user experience and promoting a more *sustainable* recommendation ecosystem. The report highlights the potential of **LLM-driven** design to foster a more *mutually beneficial* ecosystem, with benefits for users, merchants, and the platform.

## Key Contributions and Findings
*![](https://img.shields.io/badge/-**Introduction_of_RecGPT**-informational) **Introduction of RecGPT**: RecGPT is a novel framework that *rethinks* the design paradigm of recommender systems, placing **user intent** at the center of the recommendation pipeline.
* **Multi-Stage Training Paradigm**: The report proposes a *multi-stage training paradigm*, which integrates *reasoning-enhanced pre-alignment* and *self-training evolution*, guided by a **Human-LLM cooperative judge system**.
* **Intent-Centric Design**: RecGPT's **intent-centric** design transforms *log-fitting* recommendation into a more *dynamic and adaptive* process, capturing users' *evolving and latent interests*.
* **Large Language Models**: The report demonstrates the effectiveness of integrating *large language models* (**LLMs**) into key stages of the recommendation pipeline, including *user interest mining*, *item retrieval*, and *explanation generation*.
* **Real-World Deployment**: RecGPT has been fully deployed on the *Taobao App*, with online experiments demonstrating *consistent performance gains* across stakeholders.

## Methodology Overview
The methodology involves **three major components**: *user interest mining*, *item retrieval*, and *explanation generation*. The report employs **bold** techniques such as *reasoning-enhanced pre-alignment* and *self-training evolution*, guided by a **Human-LLM cooperative judge system**. The *multi-stage training paradigm* is used to effectively align *general-purpose LLMs* to *domain-specific recommendation tasks*.

## Results and Performance
The report summarizes the key results, highlighting **consistent performance gains** across stakeholders, including *increased content diversity* and *user satisfaction*, as well as *greater exposure* and *conversions* for merchants and the platform. The results demonstrate **significant improvements** in *key metrics*, such as *click-through rate* and *conversion rate*, with *statistically significant* differences compared to *baseline models*.

## Limitations and Future Work
The report mentions several limitations, including the need for *further evaluation* of RecGPT in *different domains* and *scenarios*. Potential future directions include *exploring new architectures* for **LLM-driven** recommender systems and *investigating the impact* of RecGPT on *long-tail phenomena* and *filter bubbles*.

## Practical Applications
The RecGPT framework has significant implications for *real-world applications*, including *e-commerce*, *content recommendation*, and *personalized advertising*. The report demonstrates the potential of **LLM-driven** design to foster a more *sustainable and mutually beneficial* recommendation ecosystem, with benefits for users, merchants, and the platform. The framework can be applied to *various domains*, including *social media*, *music streaming*, and *video recommendation*, to improve the overall user experience and promote *diversity and discovery*.

---

**Authors:** Chao Yi, Dian Chen, Gaoyang Guo, Jiakai Tang, Jian Wu, Jing Yu, Sunhao Dai, Wen Chen, Wenjun Yang, Yuning Jiang, Zhujin Gao, Bo Zheng, Chi Li, Dimin Wang, Dixuan Wang, Fan Li, Fan Zhang, Haibin Chen, Haozhuang Liu, Jialin Zhu, Jiamang Wang, Jiawei Wu, Jin Cui, Ju Huang, Kai Zhang, Kan Liu, Lang Tian, Liang Rao, Longbin Li, Lulu Zhao, Mao Zhang, Na He, Peiyang Wang, Qiqi Huang, Tao Luo, Wenbo Su, Xiaoxiao He, Xin Tong, Xu Chen, Xunke Xi, Yang Li, Yaxuan Wu, Yeqiu Yang, Yi Hu, Yinnan Song, Yuchen Li, Yujie Luo, Yujin Yuan, Yuliang Yan, Zhengyang Wang, Zhibo Xiao, Zhixin Ma, Zile Zhou
